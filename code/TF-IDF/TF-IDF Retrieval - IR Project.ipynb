{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import pickle\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import string\n",
    "import collections\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for cleaning corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = \"[\"+string.punctuation+\"]*\"\n",
    "timestamp_regex1 = \"[A-Za-z]+\\s[0-9]+,\\s[0-9]+\\s+[0-9]+:[0-9]+\\s[AM]*[PM]*\"\n",
    "timestamp_regex2 =\"[A-Za-z]+,\\s[0-9]+\"\n",
    "\n",
    "# Get the last index of a value from a list\n",
    "def getLastIndexOf(a_list, a_value):\n",
    "    return len(a_list) - a_list[::-1].index(a_value) - 1\n",
    "\n",
    "\n",
    "# Remove Punctuation\n",
    "def remove_punctuation(text):\n",
    "    text = re.sub(regex, '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Clean the document content\n",
    "def clean_content(text):\n",
    "    \n",
    "    # Remove html code\n",
    "    # Every document in this corpus contains only two kinds\n",
    "    # of HTML tags\n",
    "    \n",
    "    text = re.sub('<html>', '', text)\n",
    "    text = re.sub('<pre>', '', text)\n",
    "    text = re.sub('</html>', '', text)\n",
    "    text = re.sub('</pre>', '', text)\n",
    "    \n",
    "    # Remove timestamp\n",
    "    text = re.sub(timestamp_regex1, '', text)\n",
    "    \n",
    "    # Remove timestamp\n",
    "    text = re.sub(timestamp_regex2, '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = remove_punctuation(text)\n",
    "    \n",
    "    # Remove numbers towards the end of the file\n",
    "    text = re.sub('[0-9]+\\s[0-9]+\\s[0-9]+','', text)\n",
    "    \n",
    "    # Split into tokens\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def retrieve_sentences(text):\n",
    "    \n",
    "    # Remove html code\n",
    "    # Every document in this corpus contains only two kinds\n",
    "    # of HTML tags\n",
    "    \n",
    "    text = re.sub('<html>', '', text)\n",
    "    text = re.sub('<pre>', '', text)\n",
    "    text = re.sub('</html>', '', text)\n",
    "    text = re.sub('</pre>', '', text)\n",
    "    \n",
    "    # Remove timestamp\n",
    "    text = re.sub(timestamp_regex1, '', text)\n",
    "    \n",
    "    # Remove timestamp\n",
    "    text = re.sub(timestamp_regex2, '', text)\n",
    "    \n",
    "    # Remove numbers towards the end of the file\n",
    "    text = re.sub('[0-9]+\\s[0-9]+\\s[0-9]+','', text)\n",
    "    \n",
    "    # Remove tabs\n",
    "    text = re.sub('\\t', ' ', text)\n",
    "    \n",
    "    # Remove extra \\n or \\t\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Split into sentences \n",
    "    temp_sentences = re.split('\\n\\n+', text)\n",
    "    \n",
    "    # Replace \\n\n",
    "    # temp_sentences = [re.sub('\\n[A-Z]', '. ', s) for s in temp_sentences]\n",
    "    # temp_sentences = [re.sub('\\n[a-z]', ' ', s) for s in temp_sentences]\n",
    "    \n",
    "    temp_sentences = [re.sub('\\n', ' ', s) for s in temp_sentences]\n",
    "    \n",
    "    sentences = []\n",
    "    \n",
    "    for s in temp_sentences:\n",
    "        temp_s = s.split(\". \")\n",
    "        for t_s in temp_s:\n",
    "            sentences.append(t_s.strip())\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateCorpus(pickle_file_name):\n",
    "    cwd = os.getcwd()+\"/cacm/\"\n",
    "    list_dir = os.listdir(cwd)\n",
    "\n",
    "    full_corpus_dict = {}\n",
    "\n",
    "    print(\"Processing all files\")\n",
    "\n",
    "    for l in list_dir:\n",
    "        f = open(cwd+l, \"r+\")\n",
    "        doc_id = l.split(\".html\")\n",
    "        doc_content=retrieve_sentences(f.read())\n",
    "        full_corpus_dict[doc_id[0]]=doc_content\n",
    "        \n",
    "\n",
    "    pickle.dump(full_corpus_dict, open(os.getcwd()+\"/\"+pickle_file_name+\".p\", \"wb\"))\n",
    "    print(\"corpus written to pickle file\")\n",
    "    return full_corpus_dict\n",
    "\n",
    "def loadCorpus(pickle_file_name):\n",
    "    return dict(pickle.load(open(os.getcwd()+\"/\"+pickle_file_name+\".p\", \"rb\"), encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus loaded\n"
     ]
    }
   ],
   "source": [
    "corpus_dict = loadCorpus(\"corpus\")\n",
    "print(\"corpus loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['techniques',\n",
       " 'for',\n",
       " 'storage',\n",
       " 'allocation',\n",
       " 'algorithms',\n",
       " 'cacm',\n",
       " 'kelley',\n",
       " 'jr',\n",
       " 'j',\n",
       " 'e',\n",
       " 'ca611011',\n",
       " 'jb']"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_dict['CACM-0270']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Document Frequencies (DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigrams loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'CACM-0270': 1,\n",
       " 'CACM-0321': 1,\n",
       " 'CACM-0371': 2,\n",
       " 'CACM-0409': 2,\n",
       " 'CACM-0717': 1,\n",
       " 'CACM-0719': 1,\n",
       " 'CACM-0804': 1,\n",
       " 'CACM-0950': 1,\n",
       " 'CACM-1122': 1,\n",
       " 'CACM-1145': 1,\n",
       " 'CACM-1171': 2,\n",
       " 'CACM-1172': 2,\n",
       " 'CACM-1237': 1,\n",
       " 'CACM-1265': 1,\n",
       " 'CACM-1294': 1,\n",
       " 'CACM-1342': 1,\n",
       " 'CACM-1350': 1,\n",
       " 'CACM-1373': 1,\n",
       " 'CACM-1374': 1,\n",
       " 'CACM-1392': 3,\n",
       " 'CACM-1397': 1,\n",
       " 'CACM-1411': 2,\n",
       " 'CACM-1423': 1,\n",
       " 'CACM-1433': 1,\n",
       " 'CACM-1468': 1,\n",
       " 'CACM-1504': 1,\n",
       " 'CACM-1529': 2,\n",
       " 'CACM-1551': 3,\n",
       " 'CACM-1572': 1,\n",
       " 'CACM-1592': 1,\n",
       " 'CACM-1601': 1,\n",
       " 'CACM-1609': 1,\n",
       " 'CACM-1619': 1,\n",
       " 'CACM-1658': 4,\n",
       " 'CACM-1705': 1,\n",
       " 'CACM-1718': 1,\n",
       " 'CACM-1728': 1,\n",
       " 'CACM-1752': 2,\n",
       " 'CACM-1787': 1,\n",
       " 'CACM-1810': 1,\n",
       " 'CACM-1851': 1,\n",
       " 'CACM-1873': 2,\n",
       " 'CACM-1877': 3,\n",
       " 'CACM-1886': 2,\n",
       " 'CACM-1924': 5,\n",
       " 'CACM-1946': 1,\n",
       " 'CACM-1948': 1,\n",
       " 'CACM-1953': 1,\n",
       " 'CACM-1957': 1,\n",
       " 'CACM-2007': 1,\n",
       " 'CACM-2025': 1,\n",
       " 'CACM-2030': 2,\n",
       " 'CACM-2035': 2,\n",
       " 'CACM-2042': 1,\n",
       " 'CACM-2053': 2,\n",
       " 'CACM-2081': 1,\n",
       " 'CACM-2091': 1,\n",
       " 'CACM-2092': 1,\n",
       " 'CACM-2094': 2,\n",
       " 'CACM-2110': 1,\n",
       " 'CACM-2111': 1,\n",
       " 'CACM-2114': 1,\n",
       " 'CACM-2128': 1,\n",
       " 'CACM-2135': 1,\n",
       " 'CACM-2142': 2,\n",
       " 'CACM-2146': 5,\n",
       " 'CACM-2158': 1,\n",
       " 'CACM-2167': 2,\n",
       " 'CACM-2189': 1,\n",
       " 'CACM-2200': 2,\n",
       " 'CACM-2208': 1,\n",
       " 'CACM-2216': 2,\n",
       " 'CACM-2222': 1,\n",
       " 'CACM-2226': 4,\n",
       " 'CACM-2231': 1,\n",
       " 'CACM-2232': 1,\n",
       " 'CACM-2236': 1,\n",
       " 'CACM-2263': 5,\n",
       " 'CACM-2266': 1,\n",
       " 'CACM-2267': 2,\n",
       " 'CACM-2272': 2,\n",
       " 'CACM-2273': 5,\n",
       " 'CACM-2276': 2,\n",
       " 'CACM-2283': 5,\n",
       " 'CACM-2289': 5,\n",
       " 'CACM-2306': 1,\n",
       " 'CACM-2314': 1,\n",
       " 'CACM-2324': 2,\n",
       " 'CACM-2325': 4,\n",
       " 'CACM-2337': 1,\n",
       " 'CACM-2344': 1,\n",
       " 'CACM-2362': 1,\n",
       " 'CACM-2365': 1,\n",
       " 'CACM-2366': 1,\n",
       " 'CACM-2368': 2,\n",
       " 'CACM-2373': 1,\n",
       " 'CACM-2389': 2,\n",
       " 'CACM-2402': 2,\n",
       " 'CACM-2417': 1,\n",
       " 'CACM-2421': 1,\n",
       " 'CACM-2426': 1,\n",
       " 'CACM-2433': 1,\n",
       " 'CACM-2435': 1,\n",
       " 'CACM-2450': 1,\n",
       " 'CACM-2453': 1,\n",
       " 'CACM-2454': 2,\n",
       " 'CACM-2483': 3,\n",
       " 'CACM-2484': 2,\n",
       " 'CACM-2490': 3,\n",
       " 'CACM-2498': 1,\n",
       " 'CACM-2499': 2,\n",
       " 'CACM-2505': 1,\n",
       " 'CACM-2520': 1,\n",
       " 'CACM-2522': 1,\n",
       " 'CACM-2524': 1,\n",
       " 'CACM-2535': 1,\n",
       " 'CACM-2541': 1,\n",
       " 'CACM-2545': 1,\n",
       " 'CACM-2557': 1,\n",
       " 'CACM-2561': 1,\n",
       " 'CACM-2570': 1,\n",
       " 'CACM-2579': 1,\n",
       " 'CACM-2598': 2,\n",
       " 'CACM-2606': 1,\n",
       " 'CACM-2627': 4,\n",
       " 'CACM-2628': 1,\n",
       " 'CACM-2630': 2,\n",
       " 'CACM-2645': 2,\n",
       " 'CACM-2646': 2,\n",
       " 'CACM-2647': 1,\n",
       " 'CACM-2657': 1,\n",
       " 'CACM-2665': 1,\n",
       " 'CACM-2674': 4,\n",
       " 'CACM-2679': 3,\n",
       " 'CACM-2691': 1,\n",
       " 'CACM-2692': 5,\n",
       " 'CACM-2715': 1,\n",
       " 'CACM-2716': 1,\n",
       " 'CACM-2719': 1,\n",
       " 'CACM-2722': 3,\n",
       " 'CACM-2723': 1,\n",
       " 'CACM-2725': 1,\n",
       " 'CACM-2751': 1,\n",
       " 'CACM-2766': 1,\n",
       " 'CACM-2767': 5,\n",
       " 'CACM-2771': 1,\n",
       " 'CACM-2819': 4,\n",
       " 'CACM-2828': 3,\n",
       " 'CACM-2830': 1,\n",
       " 'CACM-2832': 2,\n",
       " 'CACM-2833': 1,\n",
       " 'CACM-2834': 2,\n",
       " 'CACM-2837': 1,\n",
       " 'CACM-2838': 2,\n",
       " 'CACM-2855': 1,\n",
       " 'CACM-2857': 1,\n",
       " 'CACM-2860': 2,\n",
       " 'CACM-2863': 4,\n",
       " 'CACM-2877': 1,\n",
       " 'CACM-2880': 1,\n",
       " 'CACM-2883': 1,\n",
       " 'CACM-2884': 7,\n",
       " 'CACM-2887': 1,\n",
       " 'CACM-2890': 2,\n",
       " 'CACM-2902': 6,\n",
       " 'CACM-2903': 5,\n",
       " 'CACM-2904': 2,\n",
       " 'CACM-2912': 1,\n",
       " 'CACM-2913': 1,\n",
       " 'CACM-2924': 2,\n",
       " 'CACM-2932': 1,\n",
       " 'CACM-2936': 4,\n",
       " 'CACM-2942': 1,\n",
       " 'CACM-2948': 1,\n",
       " 'CACM-2950': 6,\n",
       " 'CACM-2953': 2,\n",
       " 'CACM-2955': 1,\n",
       " 'CACM-2963': 2,\n",
       " 'CACM-2968': 2,\n",
       " 'CACM-2973': 2,\n",
       " 'CACM-2986': 1,\n",
       " 'CACM-2997': 3,\n",
       " 'CACM-3006': 5,\n",
       " 'CACM-3018': 2,\n",
       " 'CACM-3032': 2,\n",
       " 'CACM-3037': 1,\n",
       " 'CACM-3038': 1,\n",
       " 'CACM-3040': 1,\n",
       " 'CACM-3054': 1,\n",
       " 'CACM-3055': 2,\n",
       " 'CACM-3061': 1,\n",
       " 'CACM-3065': 1,\n",
       " 'CACM-3075': 2,\n",
       " 'CACM-3086': 1,\n",
       " 'CACM-3094': 1,\n",
       " 'CACM-3116': 1,\n",
       " 'CACM-3118': 1,\n",
       " 'CACM-3124': 2,\n",
       " 'CACM-3131': 2,\n",
       " 'CACM-3132': 3,\n",
       " 'CACM-3134': 2,\n",
       " 'CACM-3141': 1,\n",
       " 'CACM-3143': 1,\n",
       " 'CACM-3150': 1,\n",
       " 'CACM-3151': 2,\n",
       " 'CACM-3152': 1,\n",
       " 'CACM-3153': 2,\n",
       " 'CACM-3156': 1,\n",
       " 'CACM-3163': 3,\n",
       " 'CACM-3164': 1,\n",
       " 'CACM-3165': 1,\n",
       " 'CACM-3166': 6,\n",
       " 'CACM-3187': 1}"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load unigrams df\n",
    "\n",
    "unigram_dict=dict(pickle.load(open(os.getcwd()+\"/unigrams.p\", \"rb\"), encoding=\"utf-8\"))\n",
    "print(\"Unigrams loaded\")\n",
    "unigram_dict['algorithms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate IDF\n",
    "#IDF(t) = log_e(Total number of documents / Number of documents with term t in it)\n",
    "\n",
    "def calculateIDF(corpus_dict, unigram_dict):\n",
    "\n",
    "    idf={}\n",
    "    N = len(corpus_dict)\n",
    "    for term in unigram_dict.keys():\n",
    "        idf[term] = math.log(N/len(unigram_dict[term].keys()))\n",
    "\n",
    "    print(\"IDFs calculated!\")\n",
    "\n",
    "    pickle.dump(idf, open(\"idf.p\", \"wb\"))\n",
    "    print(\"IDFs writted to file idf.p\")\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.327223179825"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#idf = calculateIDF(corpus_dict, unigram_dict)\n",
    "# #or load from memory\n",
    "idf = dict(pickle.load(open(os.getcwd()+\"/idf.p\", \"rb\"), encoding=\"utf-8\"))\n",
    "idf['automatic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate TF-IDF for every document per query\n",
    "def queryForResults(query, unigram_dict, corpus_dict):\n",
    "\n",
    "    ranked_documents = {}\n",
    "    unigram_dict['automatic']\n",
    "    doc_list = []\n",
    "    for terms in word_tokenize(query.lower()):\n",
    "\n",
    "        # Retrieve inverted list for term\n",
    "        for k in unigram_dict[terms].keys():\n",
    "            if k not in doc_list:\n",
    "                doc_list.append(k)\n",
    "\n",
    "\n",
    "    for d in doc_list:\n",
    "        doc_len = len(corpus_dict[d])\n",
    "        score = 0.0\n",
    "        for term in word_tokenize(query.lower()):\n",
    "            if d in unigram_dict[term].keys():\n",
    "                tf_term = unigram_dict[term][d]/doc_len\n",
    "                idf_term = idf[term]\n",
    "                score+= tf_term * idf_term\n",
    "        ranked_documents[d]=score\n",
    "\n",
    "    return ranked_documents\n",
    "        \n",
    "def sortByScore(result_set):\n",
    "    return sorted(result_set.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeResultsToFile(rank_sort, file_name):\n",
    "    output=\"\"\n",
    "    f = open(file_name+\".txt\",\"w+\")\n",
    "    for i in range(100):\n",
    "        doc, score = rank_sort[i]\n",
    "        output+=str(doc)+\" : \"+str(score)+\"\\n\"\n",
    "    f.write(output)\n",
    "    f.close()\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CACM-2415', 0.3564881978383928),\n",
       " ('CACM-0145', 0.3327223179825),\n",
       " ('CACM-0034', 0.3327223179825),\n",
       " ('CACM-0193', 0.27726859831874995),\n",
       " ('CACM-0273', 0.27726859831874995)]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve results\n",
    "rank_sort = sortByScore(queryForResults(\"Automatic Implementation\",unigram_dict, corpus_dict))\n",
    "rank_sort[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 \n",
    "\n",
    "#### Removing stop words from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'about', 'above', 'accordingly', 'across']"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = [word.rstrip('\\n') for word in open('common_words')]\n",
    "stop_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda function to produce difference of two LISTS\n",
    "diff = lambda l1,l2: [x for x in l1 if x not in l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped corpus written to file\n",
      "3204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'techniques storage allocation algorithms cacm kelley jr ca611011 jb'"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate corpus - remove all stopwords\n",
    "def generateStoppedCorpus(corpus_dict, stop_words):\n",
    "\n",
    "    stopped_corpus = {}\n",
    "\n",
    "    for doc, content in corpus_dict.items():\n",
    "        temp_list = diff(content, stop_words)\n",
    "        stopped_corpus[doc] = \" \".join(temp_list)\n",
    "        pickle.dump(stopped_corpus, open(\"stopped_corpus.p\",\"wb\"))\n",
    "    print(\"Stopped corpus written to file\")\n",
    "    return stopped_corpus\n",
    "\n",
    "stopped_corpus = generateStoppedCorpus(corpus_dict, stop_words)\n",
    "print(len(stopped_corpus))\n",
    "\n",
    "stopped_corpus['CACM-0270']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'techniques storage allocation algorithms cacm kelley jr ca611011 jb'"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopped_corpus = loadCorpus(\"stopped_corpus\")\n",
    "stopped_corpus['CACM-0270']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using stemmed corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an on line program for non numer algebra the goal of thi program is to make a step toward te design of an autom mathemat assist some requir for such a program ar it must be easi to access and that the result must be obtain in a reason short time accordingli the program is written for a time share comput the q 32 comput as system develop corpor santa monica california wa chosen becaus it also had a lisp 1 5 compil program and debug wa done from a remot teletyp consol at stanford univers cacm august 1966 korsvold k ca660818 es ']"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading and parsing the stemmed corpus\n",
    "# provided in cacm_stem.txt\n",
    "# A separate function was required because loading this corpus required\n",
    "# a different set of steps for file processing\n",
    "\n",
    "def loadStemmedCorpus(file_name):\n",
    "\n",
    "    stemmed_corpus_temp = {}\n",
    "    with open(file_name) as f:\n",
    "        content = f.readlines()\n",
    "    pattern = '#\\s[0-9]+'\n",
    "    for item in content:\n",
    "        if re.match(pattern, item) :\n",
    "            doc_id = re.split('#\\s', item.strip())\n",
    "            doc_id = doc_id[1]\n",
    "            stemmed_corpus_temp[doc_id]=[]\n",
    "        else:\n",
    "            stemmed_corpus_temp[doc_id].append(item.strip())\n",
    "            \n",
    "    stemmed_corpus={}\n",
    "\n",
    "    for doc_id, content in stemmed_corpus_temp.items():\n",
    "        new_doc_id = \"CACM-\"+str(doc_id).zfill(4)\n",
    "        stemmed_corpus[new_doc_id]=[]\n",
    "        temp_list = []\n",
    "        flag = 0\n",
    "        for line in content:\n",
    "            if re.match('^ *[0-9][0-9 ]*$', line)==None:\n",
    "                temp_list.append(line)\n",
    "\n",
    "        all_content = \" \".join(temp_list)\n",
    "        \n",
    "        #Isolate and remove timestamps\n",
    "        split_content = all_content.split('[a-z]+\\s[0-9]+\\s[0-9]+\\s[0-9]+\\s[0-9]+\\s[am|pm]+')[0]\n",
    "        final_content=re.sub('[a-z]+\\s[0-9]+\\s[0-9]+\\s[0-9]+\\s[0-9]+\\s[am|pm]+[\\s0-9]*','', split_content)\n",
    "        stemmed_corpus[new_doc_id].append(final_content)\n",
    "        \n",
    "        pickle.dump(stemmed_corpus, open(\"stemmed_corpus.p\",\"wb\"))\n",
    "        print(\"Stemmed corpus written to file\")\n",
    "\n",
    "            \n",
    "    return stemmed_corpus\n",
    "\n",
    "stemmed_corpus = loadStemmedCorpus(\"cacm_stem.txt\")\n",
    "stemmed_corpus['CACM-3204']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an on line program for non numer algebra the goal of thi program is to make a step toward te design of an autom mathemat assist some requir for such a program ar it must be easi to access and that the result must be obtain in a reason short time accordingli the program is written for a time share comput the q 32 comput as system develop corpor santa monica california wa chosen becaus it also had a lisp 1 5 compil program and debug wa done from a remot teletyp consol at stanford univers cacm august 1966 korsvold k ca660818 es ']"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_corpus = loadCorpus(\"stemmed_corpus\")\n",
    "stemmed_corpus['CACM-3204']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snippet Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSnippets(rank_sort_temp, full_corpus_dict, query):\n",
    "\n",
    "    snippets = {}\n",
    "\n",
    "    for entry in rank_sort_temp:\n",
    "        document, score = entry\n",
    "        snippets[document] = []\n",
    "        \n",
    "        for s in full_corpus_dict[document]:\n",
    "            first_index = 5\n",
    "            end_index = 0\n",
    "            temp=[]\n",
    "            \n",
    "            for term in word_tokenize(query.lower()):\n",
    "                temp = word_tokenize(s)\n",
    "                temp_lower = word_tokenize(s.lower())\n",
    "                flag = False\n",
    "                if term in temp_lower :\n",
    "                    flag = True\n",
    "                    if temp_lower.index(term) < first_index :\n",
    "                        first_index = temp_lower.index(term)\n",
    "                    if getLastIndexOf(temp_lower, term) >= end_index:\n",
    "                        end_index = getLastIndexOf(temp_lower, term)\n",
    "\n",
    "                if flag == True:\n",
    "\n",
    "                    if first_index < 5 : \n",
    "                        first_index = 0\n",
    "                    else:\n",
    "                        first_index -= 5\n",
    "                    if (len(temp_lower)-end_index) < 5:\n",
    "                        end_index = len(temp_lower)\n",
    "                    else:\n",
    "                        end_index +=  5\n",
    "                    formatted_string = \"...\"+\" \".join(temp[first_index:end_index+1])+\"...\"\n",
    "                    if formatted_string not in snippets[document]:\n",
    "                        snippets[document].append(formatted_string)\n",
    "\n",
    "    return snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_sort_temp = rank_sort[:20]\n",
    "snippets = generateSnippets(rank_sort_temp, full_corpus_dict, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<html><body><h2>Retrieval results : TF-IDF </h2><h3> Query : Automatic Implementation</h3><p><h4>CACM-2415</h4>...Algorithm for <b>Automatic</b> Numerical Integration Over a Finite...<br>...<b>automatic</b> integration , numerical integration , <b>automatic</b> quadrature , numerical quadrature...<br></p><p><h4>CACM-0145</h4>...<b>Automatic</b> Graders for Programming Classes...<br></p><p><h4>CACM-0034</h4>...Tables for <b>Automatic</b> Computation...<br></p><p><h4>CACM-0193</h4>...A Start at <b>Automatic</b> Storage Assignment...<br></p><p><h4>CACM-0273</h4>...Experience in <b>Automatic</b> Storage Allocation...<br></p><p><h4>CACM-0018</h4>...Simple <b>Automatic</b> Coding Systems...<br></p><p><h4>CACM-1624</h4>...<b>Automatic</b> Dimensioning...<br>...Examples of algorithm that will accomplish <b>automatic</b> storage reservation without the need...<br></p><p><h4>CACM-2942</h4>...An Algol-Based <b>Implementation</b> of SNOBOL 4 Patterns...<br>...patterns SNOBOL 4 , pattern matching , string processing , pattern <b>implementation</b> , algorithms in Pascal...<br></p><p><h4>CACM-0098</h4>...The Arithmetic Translator-Compiler of the IBM FORTRAN <b>Automatic</b> Coding System...<br></p><p><h4>CACM-0189</h4>...The Future of <b>Automatic</b> Digital Computers...<br></p><p><h4>CACM-2239</h4>...numerical integration , integration rule , adaptive integration , <b>automatic</b> integration , Simpson 's rule , numerical quadrature , quadrature rule , adaptive quadrature , <b>automatic</b> quadrature , round-off error control...<br></p><p><h4>CACM-2074</h4>...numerical integration , integration rule , adaptive integration , <b>automatic</b> integration , Simpson 's rule , numerical quadrature , quadrature , quadrature rule , adaptive quadrature , <b>automatic</b> quadrature , round-off error control...<br></p><p><h4>CACM-0329</h4>...<b>Automatic</b> Abstracting and Indexing Survey and...<br>...In preparation for the widespread use of <b>automatic</b> scanners which will read documents and transmit their contents to other machines for analysis , this report presents a new concept in <b>automatic</b> analysis : the relative-frequency approach...<br>...The relative-frequency approach is discussed in detail , as is its application to problems of <b>automatic</b> indexing and <b>automatic</b> abstracting...<br>...Included in the report is a summary of <b>automatic</b> analysis studies published as of...<br>...Conclusions are that point toward more sophisticated mathematical and linguistic techniques for the solution of problems of <b>automatic</b> analysis ....<br></p><p><h4>CACM-0022</h4>...Unusual Applications Department -- <b>Automatic</b> <b>Implementation</b> of Computer Logic...<br></p><p><h4>CACM-0987</h4>...Basic FORTRAN ( A Programming Language for Information Processing on <b>Automatic</b> Data Processing Systems )...<br></p><p><h4>CACM-2024</h4>...<b>automatic</b> segmentation , program connectivity...<br></p><p><h4>CACM-0080</h4>...A Technique for Computing Critical Rotational Speeds of Flexible Shafts on an <b>Automatic</b> Computer...<br></p><p><h4>CACM-0274</h4>...Dynamic Storage Allocation in the Atlas Computer , Including an <b>Automatic</b> Use of a Backing Store...<br></p><p><h4>CACM-0400</h4>...Comments on the <b>Implementation</b> of Recursive Procedures and Blocks...<br></p><p><h4>CACM-1682</h4>...The <b>Implementation</b> of a BASIC System in...<br>...The <b>implementation</b> of a remote terminal BASIC...<br>...This <b>implementation</b> combines a unique mixture of...<br></p><p></p></body></html>\""
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate HTML files for Query Highlighting\n",
    "\n",
    "def generateHTML(snippets, rank_sort_temp, query):\n",
    "    \n",
    "    html_file_begin=\"<html><body><h2>Retrieval results : TF-IDF </h2>\"\n",
    "    html_file_begin+=\"<h3> Query : \"+query+\"</h3>\"\n",
    "    html_file_begin+=\"<p>\"\n",
    "\n",
    "    \n",
    "    for i in range(len(rank_sort_temp)):\n",
    "        doc, score = rank_sort_temp[i]\n",
    "        sn = snippets[doc]\n",
    "        html_file_begin+=\"<h4>\"+doc+\"</h4>\"\n",
    "        for s in sn:\n",
    "\n",
    "            for term in word_tokenize(query):\n",
    "                if term in s:\n",
    "                    s = re.sub(term, \"<b>\"+term+\"</b>\", s, re.IGNORECASE)\n",
    "                elif term.lower() in s:\n",
    "                    s = re.sub(term.lower(), \"<b>\"+term.lower()+\"</b>\", s, re.IGNORECASE)\n",
    "\n",
    "            html_file_begin+=s+\"<br>\"\n",
    "        html_file_begin+=\"</p><p>\"\n",
    "    html_file_begin+=\"</p>\"\n",
    "\n",
    "    \n",
    "    html_file_begin+=\"</body></html>\"\n",
    "    return html_file_begin\n",
    "\n",
    "html_file = generateHTML(snippets, rank_sort_temp, query)\n",
    "\n",
    "f = open(\"query_results.html\", \"w+\")\n",
    "f.write(html_file)\n",
    "f.close()\n",
    "\n",
    "html_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
